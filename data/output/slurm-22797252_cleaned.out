Working on file train_with_inverse (1 / 5)...
***** Running training *****
  Num examples = 2868
  Num Epochs = 4
  Instantaneous batch size per device = 8
  Total train batch size (w. parallel, distributed & accumulation) = 8
  Gradient Accumulation steps = 1
  Total optimization steps = 1436
***** Running Evaluation *****
  Num examples = 3101
  Batch size = 8
{'loss': 0.413, 'learning_rate': 3.259052924791087e-05, 'epoch': 1.39}
{'loss': 0.3402, 'learning_rate': 1.518105849582173e-05, 'epoch': 2.79}
{'eval_loss': 1.9699089527130127, 'eval_accuracy': 0.5543373105449855, 'eval_precision': 0.6120879120879121, 'eval_recall': 0.6223463687150838, 'eval_f1': 0.6171745152354571, 'eval_runtime': 37.0178, 'eval_samples_per_second': 83.77, 'eval_steps_per_second': 10.481, 'epoch': 2.79}
{'train_runtime': 463.6727, 'train_samples_per_second': 24.742, 'train_steps_per_second': 3.097, 'train_loss': 0.28724602935706006, 'epoch': 4.0}

Working on file train_with_new_hyponyms (2 / 5)...
***** Running training *****
  Num examples = 4956
  Num Epochs = 4
  Instantaneous batch size per device = 8
  Total train batch size (w. parallel, distributed & accumulation) = 8
  Gradient Accumulation steps = 1
  Total optimization steps = 2480
***** Running Evaluation *****
  Num examples = 3101
  Batch size = 8
***** Running Evaluation *****
  Num examples = 3101
  Batch size = 8
{'loss': 0.5431, 'learning_rate': 3.991935483870968e-05, 'epoch': 0.81}
{'loss': 0.2862, 'learning_rate': 2.9838709677419357e-05, 'epoch': 1.61}
{'eval_loss': 1.9921311140060425, 'eval_accuracy': 0.4743631086746211, 'eval_precision': 0.5426439232409381, 'eval_recall': 0.5687150837988827, 'eval_f1': 0.5553737043098744, 'eval_runtime': 37.0076, 'eval_samples_per_second': 83.794, 'eval_steps_per_second': 10.484, 'epoch': 1.61}
{'loss': 0.1495, 'learning_rate': 1.975806451612903e-05, 'epoch': 2.42}
{'loss': 0.0843, 'learning_rate': 9.67741935483871e-06, 'epoch': 3.23}
{'eval_loss': 3.738069534301758, 'eval_accuracy': 0.38439213157046115, 'eval_precision': 0.45824561403508773, 'eval_recall': 0.364804469273743, 'eval_f1': 0.4062208398133748, 'eval_runtime': 36.0756, 'eval_samples_per_second': 85.958, 'eval_steps_per_second': 10.755, 'epoch': 3.23}
{'train_runtime': 799.8784, 'train_samples_per_second': 24.784, 'train_steps_per_second': 3.1, 'train_loss': 0.21953265436234012, 'epoch': 4.0}

Working on file train_base (3 / 5)...
***** Running training *****
  Num examples = 2736
  Num Epochs = 4
  Instantaneous batch size per device = 8
  Total train batch size (w. parallel, distributed & accumulation) = 8
  Gradient Accumulation steps = 1
  Total optimization steps = 1368
***** Running Evaluation *****
  Num examples = 3101
  Batch size = 8
{'loss': 0.3842, 'learning_rate': 3.172514619883041e-05, 'epoch': 1.46}
{'loss': 0.1473, 'learning_rate': 1.3450292397660819e-05, 'epoch': 2.92}
{'eval_loss': 2.5075109004974365, 'eval_accuracy': 0.5124153498871332, 'eval_precision': 0.5966620305980529, 'eval_recall': 0.4793296089385475, 'eval_f1': 0.5315985130111526, 'eval_runtime': 36.6511, 'eval_samples_per_second': 84.609, 'eval_steps_per_second': 10.586, 'epoch': 2.92}
{'train_runtime': 441.9978, 'train_samples_per_second': 24.76, 'train_steps_per_second': 3.095, 'train_loss': 0.2013314599879304, 'epoch': 4.0}

Working on file train_with_new_hyponyms_with_new_templates (4 / 5)...
***** Running training *****
  Num examples = 18831
  Num Epochs = 4
  Instantaneous batch size per device = 8
  Total train batch size (w. parallel, distributed & accumulation) = 8
  Gradient Accumulation steps = 1
  Total optimization steps = 9416
***** Running Evaluation *****
  Num examples = 3101
  Batch size = 8
***** Running Evaluation *****
  Num examples = 3101
  Batch size = 8
***** Running Evaluation *****
  Num examples = 3101
  Batch size = 8
***** Running Evaluation *****
  Num examples = 3101
  Batch size = 8
***** Running Evaluation *****
  Num examples = 3101
  Batch size = 8
***** Running Evaluation *****
  Num examples = 3101
  Batch size = 8
***** Running Evaluation *****
  Num examples = 3101
  Batch size = 8

{'loss': 0.573, 'learning_rate': 4.734494477485132e-05, 'epoch': 0.21}
{'loss': 0.4061, 'learning_rate': 4.4689889549702635e-05, 'epoch': 0.42}
{'eval_loss': 1.801079511642456, 'eval_accuracy': 0.5172524991938084, 'eval_precision': 0.8262806236080178, 'eval_recall': 0.20726256983240224, 'eval_f1': 0.331397945511389, 'eval_runtime': 36.6892, 'eval_samples_per_second': 84.521, 'eval_steps_per_second': 10.575, 'epoch': 0.42}
{'loss': 0.3639, 'learning_rate': 4.2034834324553954e-05, 'epoch': 0.64}
{'loss': 0.3258, 'learning_rate': 3.937977909940527e-05, 'epoch': 0.85}
{'eval_loss': 2.22963547706604, 'eval_accuracy': 0.5804579168010319, 'eval_precision': 0.8419580419580419, 'eval_recall': 0.33631284916201115, 'eval_f1': 0.4806387225548902, 'eval_runtime': 36.7549, 'eval_samples_per_second': 84.37, 'eval_steps_per_second': 10.556, 'epoch': 0.85}
{'loss': 0.3069, 'learning_rate': 3.672472387425659e-05, 'epoch': 1.06}
{'loss': 0.2605, 'learning_rate': 3.4069668649107906e-05, 'epoch': 1.27}
{'eval_loss': 2.4121739864349365, 'eval_accuracy': 0.5033860045146726, 'eval_precision': 0.7306273062730627, 'eval_recall': 0.2212290502793296, 'eval_f1': 0.33962264150943394, 'eval_runtime': 36.6875, 'eval_samples_per_second': 84.525, 'eval_steps_per_second': 10.576, 'epoch': 1.27}
{'loss': 0.2066, 'learning_rate': 3.141461342395922e-05, 'epoch': 1.49}
{'loss': 0.1155, 'learning_rate': 2.875955819881054e-05, 'epoch': 1.7}
{'eval_loss': 2.288313865661621, 'eval_accuracy': 0.6343115124153499, 'eval_precision': 0.8430962343096234, 'eval_recall': 0.45027932960893857, 'eval_f1': 0.5870356882738529, 'eval_runtime': 36.0945, 'eval_samples_per_second': 85.913, 'eval_steps_per_second': 10.75, 'epoch': 1.7}
{'loss': 0.0947, 'learning_rate': 2.6104502973661855e-05, 'epoch': 1.91}
{'loss': 0.0505, 'learning_rate': 2.344944774851317e-05, 'epoch': 2.12}
{'eval_loss': 2.463951826095581, 'eval_accuracy': 0.6668816510802967, 'eval_precision': 0.7900383141762453, 'eval_recall': 0.575977653631285, 'eval_f1': 0.6662358642972537, 'eval_runtime': 36.021, 'eval_samples_per_second': 86.089, 'eval_steps_per_second': 10.771, 'epoch': 2.12}
{'loss': 0.0403, 'learning_rate': 2.0794392523364487e-05, 'epoch': 2.34}
{'loss': 0.0295, 'learning_rate': 1.8139337298215803e-05, 'epoch': 2.55}
{'eval_loss': 3.48382306098938, 'eval_accuracy': 0.6043211867139633, 'eval_precision': 0.8670143415906127, 'eval_recall': 0.3715083798882682, 'eval_f1': 0.5201407899882674, 'eval_runtime': 36.0761, 'eval_samples_per_second': 85.957, 'eval_steps_per_second': 10.755, 'epoch': 2.55}
{'loss': 0.0393, 'learning_rate': 1.5484282073067123e-05, 'epoch': 2.76}
{'loss': 0.0263, 'learning_rate': 1.2829226847918437e-05, 'epoch': 2.97}
{'eval_loss': 2.586366653442383, 'eval_accuracy': 0.7126733311834892, 'eval_precision': 0.8799661876584953, 'eval_recall': 0.5815642458100558, 'eval_f1': 0.7003027245206862, 'eval_runtime': 36.0115, 'eval_samples_per_second': 86.111, 'eval_steps_per_second': 10.774, 'epoch': 2.97}
{'train_runtime': 2305.749, 'train_samples_per_second': 32.668, 'train_steps_per_second': 4.084, 'train_loss': 0.2027850971221924, 'epoch': 2.97}

Working on file train_with_pegasus (5 / 5)...
***** Running training *****
  Num examples = 19484
  Num Epochs = 4
  Instantaneous batch size per device = 8
  Total train batch size (w. parallel, distributed & accumulation) = 8
  Gradient Accumulation steps = 1
  Total optimization steps = 9744
***** Running Evaluation *****
  Num examples = 3101
  Batch size = 8
***** Running Evaluation *****
  Num examples = 3101
  Batch size = 8
***** Running Evaluation *****
  Num examples = 3101
  Batch size = 8
***** Running Evaluation *****
  Num examples = 3101
  Batch size = 8
***** Running Evaluation *****
  Num examples = 3101
  Batch size = 8
***** Running Evaluation *****
  Num examples = 3101
  Batch size = 8
***** Running Evaluation *****
  Num examples = 3101
  Batch size = 8
***** Running Evaluation *****
  Num examples = 3101
  Batch size = 8
***** Running Evaluation *****
  Num examples = 3101
  Batch size = 8
{'loss': 0.4095, 'learning_rate': 4.743431855500821e-05, 'epoch': 0.21}
{'loss': 0.2137, 'learning_rate': 4.486863711001642e-05, 'epoch': 0.41}
{'eval_loss': 1.5274150371551514, 'eval_accuracy': 0.6830054821025475, 'eval_precision': 0.654302103250478, 'eval_recall': 0.9558659217877095, 'eval_f1': 0.776844494892168, 'eval_runtime': 35.8662, 'eval_samples_per_second': 86.46, 'eval_steps_per_second': 10.818, 'epoch': 0.41}
{'loss': 0.1689, 'learning_rate': 4.230295566502464e-05, 'epoch': 0.62}
{'loss': 0.117, 'learning_rate': 3.9737274220032846e-05, 'epoch': 0.82}
{'eval_loss': 3.3940320014953613, 'eval_accuracy': 0.5304740406320542, 'eval_precision': 0.5902702702702702, 'eval_recall': 0.6100558659217877, 'eval_f1': 0.5999999999999999, 'eval_runtime': 36.0431, 'eval_samples_per_second': 86.036, 'eval_steps_per_second': 10.765, 'epoch': 0.82}
{'loss': 0.1055, 'learning_rate': 3.7171592775041055e-05, 'epoch': 1.03}
{'loss': 0.0965, 'learning_rate': 3.4605911330049265e-05, 'epoch': 1.23}
{'eval_loss': 2.207704544067383, 'eval_accuracy': 0.689455014511448, 'eval_precision': 0.6738125262715426, 'eval_recall': 0.8955307262569833, 'eval_f1': 0.7690093547613336, 'eval_runtime': 35.8585, 'eval_samples_per_second': 86.479, 'eval_steps_per_second': 10.82, 'epoch': 1.23}
{'loss': 0.0886, 'learning_rate': 3.2040229885057474e-05, 'epoch': 1.44}
{'loss': 0.0747, 'learning_rate': 2.947454844006568e-05, 'epoch': 1.64}
{'eval_loss': 2.2081410884857178, 'eval_accuracy': 0.6807481457594324, 'eval_precision': 0.6705029838022165, 'eval_recall': 0.8787709497206704, 'eval_f1': 0.7606382978723404, 'eval_runtime': 36.0415, 'eval_samples_per_second': 86.04, 'eval_steps_per_second': 10.765, 'epoch': 1.64}
{'loss': 0.0827, 'learning_rate': 2.6908866995073896e-05, 'epoch': 1.85}
{'loss': 0.0803, 'learning_rate': 2.4343185550082105e-05, 'epoch': 2.05}
{'eval_loss': 3.9052610397338867, 'eval_accuracy': 0.4601741373750403, 'eval_precision': 0.5320088300220751, 'eval_recall': 0.5385474860335195, 'eval_f1': 0.535258189894503, 'eval_runtime': 35.9675, 'eval_samples_per_second': 86.217, 'eval_steps_per_second': 10.788, 'epoch': 2.05}
{'loss': 0.0585, 'learning_rate': 2.1777504105090314e-05, 'epoch': 2.26}
{'loss': 0.0568, 'learning_rate': 1.921182266009852e-05, 'epoch': 2.46}
{'eval_loss': 4.168469429016113, 'eval_accuracy': 0.27249274427604, 'eval_precision': 0.26272912423625255, 'eval_recall': 0.1441340782122905, 'eval_f1': 0.18614718614718617, 'eval_runtime': 35.9488, 'eval_samples_per_second': 86.262, 'eval_steps_per_second': 10.793, 'epoch': 2.46}
{'loss': 0.0558, 'learning_rate': 1.6646141215106733e-05, 'epoch': 2.67}
{'loss': 0.0471, 'learning_rate': 1.4080459770114942e-05, 'epoch': 2.87}
{'eval_loss': 3.473564386367798, 'eval_accuracy': 0.5769106739761367, 'eval_precision': 0.6192614770459082, 'eval_recall': 0.6932960893854748, 'eval_f1': 0.6541908276225619, 'eval_runtime': 35.8769, 'eval_samples_per_second': 86.434, 'eval_steps_per_second': 10.815, 'epoch': 2.87}
{'loss': 0.043, 'learning_rate': 1.1514778325123153e-05, 'epoch': 3.08}
{'loss': 0.0453, 'learning_rate': 8.949096880131364e-06, 'epoch': 3.28}
{'eval_loss': 2.7766735553741455, 'eval_accuracy': 0.6559174459851661, 'eval_precision': 0.6616003576218149, 'eval_recall': 0.8268156424581006, 'eval_f1': 0.7350384901912094, 'eval_runtime': 35.9838, 'eval_samples_per_second': 86.178, 'eval_steps_per_second': 10.783, 'epoch': 3.28}
{'loss': 0.0345, 'learning_rate': 6.383415435139574e-06, 'epoch': 3.49}
{'loss': 0.0447, 'learning_rate': 3.817733990147783e-06, 'epoch': 3.69}
{'eval_loss': 4.0929975509643555, 'eval_accuracy': 0.5185424056755885, 'eval_precision': 0.5817281232801321, 'eval_recall': 0.5905027932960893, 'eval_f1': 0.5860826171333517, 'eval_runtime': 35.9468, 'eval_samples_per_second': 86.266, 'eval_steps_per_second': 10.794, 'epoch': 3.69}
{'loss': 0.0304, 'learning_rate': 1.2520525451559936e-06, 'epoch': 3.9}
{'train_runtime': 3115.1686, 'train_samples_per_second': 25.018, 'train_steps_per_second': 3.128, 'train_loss': 0.09595498437756192, 'epoch': 4.0}


###############################################################################
Peregrine Cluster
Job 22797252 for user 's2976129'
Finished at: Sat Jan 15 17:46:23 CET 2022

Job details:
============

Job ID              : 22797252
Name                : data_experiment_job
User                : s2976129
Partition           : gpu
Nodes               : pg-gpu42
Number of Nodes     : 1
Cores               : 12
Number of Tasks     : 1
State               : COMPLETED
Submit              : 2022-01-15T15:45:24
Start               : 2022-01-15T15:45:24
End                 : 2022-01-15T17:46:22
Reserved walltime   : 1-00:00:00
Used walltime       :   02:00:58
Used CPU time       :   01:59:23 (efficiency:  8.22%)
% User (Computation): 65.29%
% System (I/O)      : 34.71%
Mem reserved        : 8000M/node
Max Mem (Node/step) : 2.19G (pg-gpu42, per node)
Full Max Mem usage  : 2.19G
Total Disk Read     : 8.09M
Total Disk Write    : 34.50K
Average GPU usage   : 88.5% (pg-gpu42)


Acknowledgements:
=================

Please see this page for information about acknowledging Peregrine in your publications:

https://wiki.hpc.rug.nl/peregrine/introduction/scientific_output

################################################################################
